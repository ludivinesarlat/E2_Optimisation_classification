{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>jour_publication</th>\n",
       "      <th>auteur</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pour les galeries d’art, une situation moins s...</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Roxana Azimi']</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quand la masturbation provoque une hémorragie ...</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Marc Gozlan']</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Les pistes de la France pour améliorer les ter...</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Julien Bouissou']</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook et Apple se livrent une guerre ouverte</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Alexandre Piquard']</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kent Walker : « Google agit selon les lois, et...</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Kent Walker']</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39311</th>\n",
       "      <td>Christina Milian : cet achat complètement impu...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39312</th>\n",
       "      <td>Matt Pokora confiné : il partage une photo tro...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39313</th>\n",
       "      <td>Meghan, Harry et Archie : que font-ils pendant...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39314</th>\n",
       "      <td>Megxit : quels membres de la famille royale su...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39315</th>\n",
       "      <td>Mort de Pape Diouf : Florian Thauvin, Djibril ...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39316 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   titre jour_publication  \\\n",
       "0      Pour les galeries d’art, une situation moins s...       01-02-2021   \n",
       "1      Quand la masturbation provoque une hémorragie ...       01-02-2021   \n",
       "2      Les pistes de la France pour améliorer les ter...       01-02-2021   \n",
       "3        Facebook et Apple se livrent une guerre ouverte       01-02-2021   \n",
       "4      Kent Walker : « Google agit selon les lois, et...       01-02-2021   \n",
       "...                                                  ...              ...   \n",
       "39311  Christina Milian : cet achat complètement impu...       2020-04-01   \n",
       "39312  Matt Pokora confiné : il partage une photo tro...       2020-04-01   \n",
       "39313  Meghan, Harry et Archie : que font-ils pendant...       2020-04-01   \n",
       "39314  Megxit : quels membres de la famille royale su...       2020-04-01   \n",
       "39315  Mort de Pape Diouf : Florian Thauvin, Djibril ...       2020-04-01   \n",
       "\n",
       "                      auteur   journal  \n",
       "0           ['Roxana Azimi']  Le Monde  \n",
       "1            ['Marc Gozlan']  Le Monde  \n",
       "2        ['Julien Bouissou']  Le Monde  \n",
       "3      ['Alexandre Piquard']  Le Monde  \n",
       "4            ['Kent Walker']  Le Monde  \n",
       "...                      ...       ...  \n",
       "39311                    NaN    Closer  \n",
       "39312                    NaN    Closer  \n",
       "39313                    NaN    Closer  \n",
       "39314                    NaN    Closer  \n",
       "39315                    NaN    Closer  \n",
       "\n",
       "[39316 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "#df = df[df.journal!='Libération']\n",
    "#df = df[df.journal!='Le Parisien']\n",
    "#df = df[df.journal!=\"L'Express\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération dans le package des stop-mots\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('french')\n",
    "stop_words.extend([\"c'est\",\"j'ai\",\"a\",\"plus\",\"contre\",\"après\", \"d'un\",\"d'une\",\"entre\",\"ans\",\"deux\",\"veut\",\"comme\",\n",
    "\"va\",\"trois\",\"sous\",\"faut\",\"n'est\",\"cinq\",\"leurs\",\"doit\",\"qu'il\",\"peut\",\"n'a\",\"mis\",\"six\",\"cette\",\"j'ai\",\"-\",\"s'est\",\"dit\",\"dont\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer #import utilisé pour raciniser les mots , finalement pas utilisé\n",
    "\n",
    "# fonction qui enlève les caractères spéciaux\n",
    "def nettoyage(text):\n",
    "    stemmer = FrenchStemmer()\n",
    "    text = str(text).lower() # mettre les mots en minuscule\n",
    "    text = re.sub(r\"[.,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)  # Retrait les caractères spéciaux :\n",
    "    text = re.sub(r\"\\&\\S*\\s\", \"\", text)\n",
    "    text = re.sub(r\"\\d\", \"\", text) \n",
    "    text = re.sub(r\"\\-\", \"\", text) \n",
    "    text = re.sub(r\"\\:\", \"\", text)\n",
    "    text = re.sub(r\"\\»\", \"\", text) \n",
    "    text = re.sub(r\"\\«\", \"\", text)\n",
    "    text = re.sub(r\"\\’\", \" \", text)\n",
    "    text = text.split()\n",
    "    les_mots = \"\"\n",
    "    for mot in text:\n",
    "        a_ajouter = stemmer.stem(mot)\n",
    "        if a_ajouter not in stop_words:\n",
    "            les_mots = les_mots + \" \"+ a_ajouter\n",
    "    return les_mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat(x):\n",
    "        if x ==\"Le Monde\":\n",
    "            val = 1\n",
    "        elif x== \"Libération\":\n",
    "            val = 2\n",
    "        elif x ==\"Le Parisien\":\n",
    "            val = 3\n",
    "        elif x == \"L'Express\":\n",
    "            val = 4\n",
    "        elif x == \"Closer\":\n",
    "            val = 5\n",
    "  \n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.titre = df.titre.map(lambda x : nettoyage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>jour_publication</th>\n",
       "      <th>auteur</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>galer art situat moin sombr redout</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Roxana Azimi']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quand masturb provoqu hémorrag méning</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Marc Gozlan']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pist franc amélior term accord libreéchang me...</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Julien Bouissou']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook apple livrent guerr ouvert</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Alexandre Piquard']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kent walk googl agit selon lois non selon pol...</td>\n",
       "      <td>01-02-2021</td>\n",
       "      <td>['Kent Walker']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39311</th>\n",
       "      <td>christin milian cet achat complet impuls qu'e...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39312</th>\n",
       "      <td>matt pokor confin partag photo trop mignon en...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39313</th>\n",
       "      <td>meghan harry archi fontil pend confin</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39314</th>\n",
       "      <td>megx quel membr famill royal succèdent harry ...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39315</th>\n",
       "      <td>mort pap diouf florian thauvin djibril ciss p...</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39316 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   titre jour_publication  \\\n",
       "0                     galer art situat moin sombr redout       01-02-2021   \n",
       "1                  quand masturb provoqu hémorrag méning       01-02-2021   \n",
       "2       pist franc amélior term accord libreéchang me...       01-02-2021   \n",
       "3                    facebook apple livrent guerr ouvert       01-02-2021   \n",
       "4       kent walk googl agit selon lois non selon pol...       01-02-2021   \n",
       "...                                                  ...              ...   \n",
       "39311   christin milian cet achat complet impuls qu'e...       2020-04-01   \n",
       "39312   matt pokor confin partag photo trop mignon en...       2020-04-01   \n",
       "39313              meghan harry archi fontil pend confin       2020-04-01   \n",
       "39314   megx quel membr famill royal succèdent harry ...       2020-04-01   \n",
       "39315   mort pap diouf florian thauvin djibril ciss p...       2020-04-01   \n",
       "\n",
       "                      auteur  journal  \n",
       "0           ['Roxana Azimi']        1  \n",
       "1            ['Marc Gozlan']        1  \n",
       "2        ['Julien Bouissou']        1  \n",
       "3      ['Alexandre Piquard']        1  \n",
       "4            ['Kent Walker']        1  \n",
       "...                      ...      ...  \n",
       "39311                    NaN        5  \n",
       "39312                    NaN        5  \n",
       "39313                    NaN        5  \n",
       "39314                    NaN        5  \n",
       "39315                    NaN        5  \n",
       "\n",
       "[39316 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.journal = df.journal.map(lambda x : encode_cat(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27521,) (11795,) (27521,) (11795,)\n"
     ]
    }
   ],
   "source": [
    "X = df.titre\n",
    "y = df['journal']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27521,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    5992\n",
       "1    5614\n",
       "2    5547\n",
       "4    5217\n",
       "3    5151\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2534\n",
       "2    2417\n",
       "1    2386\n",
       "3    2240\n",
       "4    2218\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.217725\n",
      "1    0.203990\n",
      "2    0.201555\n",
      "4    0.189564\n",
      "3    0.187166\n",
      "Name: journal, dtype: float64\n",
      "5    0.214837\n",
      "2    0.204917\n",
      "1    0.202289\n",
      "3    0.189911\n",
      "4    0.188046\n",
      "Name: journal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts().apply(lambda x: x/len(y_train)))\n",
    "print(y_test.value_counts().apply(lambda x: x/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING Vectorisation et pondération"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "corpus = X_train.to_list()\n",
    "vectorizer.fit(corpus)\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary= vectorizer.get_feature_names())),\n",
    "                 ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "\n",
    "df_tfidf = pipe.transform(corpus).toarray()\n",
    "print(np.shape(df_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## commentaires\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(analyzer='word')\n",
    "tfidf.fit(X_train)\n",
    "X_train_word_features = tfidf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Flask_journaux/src/models_pickle/file_tfidf.pkl' \n",
    "pickle.dump(tfidf, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modèle KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning KMM...\n",
      "Accurancy 0.5190334887664264\n",
      "Precision 0.534041249404564\n",
      "Recall 0.5190334887664264\n",
      "f1-score 0.5217686644967492\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "with mlflow.start_run():\n",
    "    print(\"Tuning KMM...\")\n",
    "    knn = KNeighborsClassifier()    \n",
    "    knn.fit(X_train_word_features, y_train)\n",
    "    pred_knn = knn.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_knn))\n",
    "    print('Precision', precision_score(y_test, pred_knn ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_knn,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_knn,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1054,  720,  204,  330,   78],\n",
       "       [ 611, 1184,  188,  326,  108],\n",
       "       [ 409,  502,  999,  258,   72],\n",
       "       [ 583,  565,  248,  759,   63],\n",
       "       [  99,  165,   73,   71, 2126]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.44      0.41      2386\n",
      "           2       0.38      0.49      0.43      2417\n",
      "           3       0.58      0.45      0.51      2240\n",
      "           4       0.44      0.34      0.38      2218\n",
      "           5       0.87      0.84      0.85      2534\n",
      "\n",
      "    accuracy                           0.52     11795\n",
      "   macro avg       0.53      0.51      0.52     11795\n",
      "weighted avg       0.53      0.52      0.52     11795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Flask_journaux/src/models_pickle/file_model_fitted_Knn.pkl' \n",
    "pickle.dump(knn, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modèle Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Randomforest...\n",
      "Accurancy 0.5676133955065705\n",
      "Precision 0.5645434329134511\n",
      "Recall 0.5676133955065705\n",
      "f1-score 0.55915013905046\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "with mlflow.start_run():\n",
    "    print(\"Tuning Randomforest...\")\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train_word_features, y_train)\n",
    "    pred_rf = rf.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_rf))\n",
    "    print('Precision', precision_score(y_test, pred_rf ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_rf,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_rf,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 935,  741,  202,  309,  199],\n",
       "       [ 346, 1498,  160,  265,  148],\n",
       "       [ 340,  382, 1073,  252,  193],\n",
       "       [ 401,  523,  241,  897,  156],\n",
       "       [  61,  102,   47,   32, 2292]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul de la matrise de confusion \n",
    "confusion_matrix(y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.39      0.42      2386\n",
      "           2       0.46      0.62      0.53      2417\n",
      "           3       0.62      0.48      0.54      2240\n",
      "           4       0.51      0.40      0.45      2218\n",
      "           5       0.77      0.90      0.83      2534\n",
      "\n",
      "    accuracy                           0.57     11795\n",
      "   macro avg       0.56      0.56      0.55     11795\n",
      "weighted avg       0.56      0.57      0.56     11795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MODELE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n",
      "Accurancy 0.5929631199660873\n",
      "Precision 0.5989666598775786\n",
      "Recall 0.5929631199660873\n",
      "f1-score 0.5938089391381794\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "with mlflow.start_run():\n",
    "    print(\"Tuning SVM...\")\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train_word_features, y_train)\n",
    "    pred_svm = svm.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm))\n",
    "    print('Precision', precision_score(y_test, pred_svm ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_svm,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1217,  548,  172,  377,   72],\n",
       "       [ 613, 1249,  169,  310,   76],\n",
       "       [ 369,  311, 1211,  268,   81],\n",
       "       [ 518,  408,  217, 1010,   65],\n",
       "       [  60,   80,   56,   31, 2307]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.51      0.47      2386\n",
      "           2       0.48      0.52      0.50      2417\n",
      "           3       0.66      0.54      0.60      2240\n",
      "           4       0.51      0.46      0.48      2218\n",
      "           5       0.89      0.91      0.90      2534\n",
      "\n",
      "    accuracy                           0.59     11795\n",
      "   macro avg       0.60      0.59      0.59     11795\n",
      "weighted avg       0.60      0.59      0.59     11795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Hyperparamètres & Modèle KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.536184 using {'weights': 'distance', 'n_neighbors': 9, 'metric': 'euclidean'}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Tuning KMM...\")\n",
    "    knn = KNeighborsClassifier()\n",
    "    n_neighbors = range(1, 21, 2)\n",
    "    weights = ['uniform', 'distance']\n",
    "    metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "\n",
    "    # define grid search\n",
    "    params_knn = dict(n_neighbors = n_neighbors , weights = weights, metric = metric)\n",
    "    cv_knn = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_knn = RandomizedSearchCV(estimator=knn, param_distributions = params_knn, n_jobs=-1, cv=cv_knn, scoring='accuracy',error_score=0)\n",
    "    random_result_knn = random_search_knn.fit(X_train_word_features, y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (random_result_knn.best_score_, random_result_knn.best_params_))\n",
    "    mlflow.log_param('best_params',random_result_knn.best_params_)\n",
    "    mlflow.log_metric(\"score\", random_result_knn.best_score_)\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Traning best model Knn...\")\n",
    "    knn_opti = KNeighborsClassifier(n_neighbors = 9 , weights = 'distance', metric ='euclidean')\n",
    "    knn_opti.fit(X_train_word_features, y_train)\n",
    "    pred_rf_opti = knn_opti.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_rf_opti))\n",
    "    print('Precision', precision_score(y_test, pred_rf_opti ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_knn = 'Flask_journaux/src/models_pickle/file_model_fitted_knn_opti.pkl' \n",
    "pickle.dump(knn_opti, open(file_rf, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparamètres & Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.593402 using {'n_estimators': 200, 'max_features': 'log2'}\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Tuning Randomforest...\")\n",
    "    model_forest = RandomForestClassifier()\n",
    "    n_estimators = [10,100,200]\n",
    "    max_features = ['sqrt', 'log2']\n",
    "\n",
    "    params_forest = dict(n_estimators = n_estimators, max_features = max_features)\n",
    "    cv_forest = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_forest = RandomizedSearchCV(estimator = model_forest, param_distributions = params_forest, n_jobs=-1, cv=cv_forest, scoring='accuracy',error_score=0)\n",
    "    random_result_forest = random_search_forest.fit(X_train_word_features, y_train)\n",
    "\n",
    "    print(\"Best: %f using %s\" % (random_result_forest.best_score_, random_result_forest.best_params_))\n",
    "    mlflow.log_param('best_params',random_result_forest.best_params_)\n",
    "    mlflow.log_metric(\"best_score\", random_result_forest.best_score_)\n",
    "    mlflow.sklearn.log_model(RandomForestClassifier(), \"journaux\")\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Tuning Randomforest...\")\n",
    "    rf_opti = RandomForestClassifier(n_estimators=200,max_features=log2)\n",
    "    rf_opti.fit(X_train_word_features, y_train)\n",
    "    pred_rf_opti = rf_opti.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_rf_opti))\n",
    "    print('Precision', precision_score(y_test, pred_rf_opti ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rf = 'Flask_journaux/src/models_pickle/file_model_fitted_RandonForest.pkl' \n",
    "pickle.dump(rf_opti, open(file_rf, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.3. Hyperparamètres & MODELE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    print(\"Tuning SVM...\")\n",
    "    svm = SVC()\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    C = [50, 10, 1.0, 0.1, 0.01]\n",
    "    gamma = ['scale']\n",
    "\n",
    "    # define grid search\n",
    "    params_svm = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "    cv_svm = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_SVM = RandomizedSearchCV(estimator=svm, param_distributions=params_svm, n_jobs=-1, cv=cv_svm, scoring='accuracy',error_score=0)\n",
    "    random_result_SVM = random_search_SVM.fit(X_train_word_features, y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (random_result_SVM.best_score_, random_result_SVM.best_params_))\n",
    "    mlflow.log_param('best_params',random_result_SVM.best_params_)\n",
    "    mlflow.log_metric(\"best_score\", random_result_SVM.best_score_)\n",
    "    mlflow.sklearn.log_model(SVC(), \"journaux\")\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Training best model SVM...\")\n",
    "    svm_opti = SVC(kernel = ['poly', 'rbf', 'sigmoid'], C = 50, gamma = 'scale')\n",
    "    svm_opti.fit(X_train_word_features, y_train)\n",
    "    pred_svm_opti = svm_opti.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm_opti))\n",
    "    print('Precision', precision_score(y_test, pred_svm_opti ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm_opti,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_svm_opti,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51752952 0.51889535 0.50999273 0.51580669 0.515625  ]\n",
      "cv_scores6 mean:0.5155698572122595\n",
      "[0.53605813 0.52925145 0.52579942 0.53143169 0.52525436]\n",
      "cv_scores19 mean:0.5295590095156623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#create a new KNN model\n",
    "knn6 = KNeighborsClassifier(n_neighbors=6)\n",
    "knn19 = KNeighborsClassifier(n_neighbors=19)\n",
    "cv_scores6 = cross_val_score(knn6, X_train_word_features, y_train, cv=5)\n",
    "cv_scores19 = cross_val_score(knn19, X_train_word_features, y_train, cv=5)\n",
    "\n",
    "print(cv_scores6)\n",
    "print(\"cv_scores6 mean:{}\".format(np.mean(cv_scores6)))\n",
    "print(cv_scores19)\n",
    "print(\"cv_scores19 mean:{}\".format(np.mean(cv_scores19)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 = knn6.fit(X_train_word_features, y_train)\n",
    "\n",
    "file6 = 'Flask_journaux/src/models_pickle/file_model_fitted_Knn6.pkl' \n",
    "pickle.dump(results6, open(file6, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results19 = knn19.fit(X_train_word_features, y_train)\n",
    "\n",
    "file19 = 'Flask_journaux/src/models_pickle/file_model_fitted_Knn19.pkl' \n",
    "pickle.dump(results19, open(file19, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat6 = results6.predict(test_features)\n",
    "y_hat_proba6 = results6.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat19 = results19.predict(test_features)\n",
    "y_hat_proba19 = results19.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1082,  714,  185,  332,   73],\n",
       "       [ 624, 1194,  182,  310,  107],\n",
       "       [ 420,  504, 1005,  240,   71],\n",
       "       [ 599,  560,  235,  760,   64],\n",
       "       [  90,  171,   69,   60, 2144]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 962,  699,  214,  394,  117],\n",
       "       [ 520, 1161,  206,  356,  174],\n",
       "       [ 325,  498, 1034,  273,  110],\n",
       "       [ 447,  571,  225,  878,   97],\n",
       "       [  54,  134,   49,   50, 2247]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy6 0.5243747350572276\n",
      "Precision 0.5407635311686833\n",
      "Recall 0.5243747350572276\n",
      "f1-score 0.5270738032755025\n"
     ]
    }
   ],
   "source": [
    "print('Accurancy6', accuracy_score(y_test, y_hat6))\n",
    "print('Precision', precision_score(y_test, y_hat6 ,average='weighted'))\n",
    "print('Recall', recall_score(y_test, y_hat6,average='weighted'))\n",
    "print('f1-score', f1_score(y_test, y_hat6,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy19 0.5325985587113183\n",
      "Precision 0.5361134648890626\n",
      "Recall 0.5325985587113183\n",
      "f1-score 0.5308148634241694\n"
     ]
    }
   ],
   "source": [
    "print('Accurancy19', accuracy_score(y_test, y_hat19))\n",
    "print('Precision', precision_score(y_test, y_hat19,average='weighted' ))\n",
    "print('Recall', recall_score(y_test, y_hat19,average='weighted'))\n",
    "print('f1-score', f1_score(y_test, y_hat19,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.20      0.22      2406\n",
      "           2       0.22      0.40      0.29      2392\n",
      "           3       0.22      0.62      0.32      2302\n",
      "           4       0.70      0.09      0.16      2185\n",
      "           5       0.53      0.07      0.12      2192\n",
      "           6       0.97      0.18      0.30      2604\n",
      "\n",
      "    accuracy                           0.26     14081\n",
      "   macro avg       0.48      0.26      0.23     14081\n",
      "weighted avg       0.48      0.26      0.24     14081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.03      0.05      2406\n",
      "           2       0.19      0.77      0.30      2392\n",
      "           3       0.19      0.29      0.23      2302\n",
      "           4       0.67      0.03      0.06      2185\n",
      "           5       0.58      0.04      0.07      2192\n",
      "           6       0.96      0.08      0.15      2604\n",
      "\n",
      "    accuracy                           0.21     14081\n",
      "   macro avg       0.51      0.21      0.14     14081\n",
      "weighted avg       0.51      0.21      0.15     14081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réglage hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=19, weights = 'uniform', metric = 'euclidean') \n",
    "#model = LogisticRegression(solver='liblinear')\n",
    "results = model.fit(X_train, y_train)\n",
    "\n",
    "file = 'Flask_journaux/models_pickle/file_model_fitted_Knn.pkl' \n",
    "pickle.dump(results, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = results.predict(X_test)\n",
    "y_hat_proba = results.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  66, 1601,  697,    6,   34,    2],\n",
       "       [  13, 1850,  510,    8,   10,    1],\n",
       "       [   1, 1625,  676,    0,    0,    0],\n",
       "       [  16, 1484,  596,   70,   16,    3],\n",
       "       [  32, 1508,  543,   19,   87,    3],\n",
       "       [  12, 1790,  584,    2,    4,  212]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy 0.21028336055677863\n"
     ]
    }
   ],
   "source": [
    "print('Accurancy', accuracy_score(y_test, y_hat))\n",
    "print('Precision', precision_score(y_test, y_hat,average='weighted' ))\n",
    "print('Recall', recall_score(y_test, y_hat,average='weighted'))\n",
    "print('f1-score', f1_score(y_test, y_hat,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DU MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Model columns loaded\n",
      "vector transfo loaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"Flask_journaux/models_pickle/file_model_fitted_Knn.pkl\", 'rb') as file_model:\n",
    "    lr = pickle.load(file_model)  \n",
    "    print ('Model loaded')\n",
    "\n",
    "with open(\"Flask_journaux/models_pickle/file_columns_model.pkl\", 'rb') as file_columns:\n",
    "    model_columns = pickle.load(file_columns)\n",
    "    print ('Model columns loaded')\n",
    "\n",
    "with open(\"Flask_journaux/models_pickle/file_vectorization.pkl\", 'rb') as vector:\n",
    "    vectorization = pickle.load(vector)\n",
    "    print ('vector transfo loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bob mould trent an distors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x18614 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "titre ='Bob Mould, trente ans de distorsion'\n",
    "titre_nettoyé = nettoyage(titre)\n",
    "print(titre_nettoyé)\n",
    "query = vectorization.transform([titre_nettoyé])\n",
    "query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18614)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
