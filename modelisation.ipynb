{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                         user='root',\n",
    "                         password='Ludi24',\n",
    "                         db='journaux')\n",
    "# create cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "query_read = \"Select * from articles  where jour_publication<=date('2021-04-20') and  jour_publication>=date('2020-9-10')\"\n",
    "cursor.execute(query_read)\n",
    "raw = cursor.fetchall()\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_article</th>\n",
       "      <th>titre</th>\n",
       "      <th>jour_publication</th>\n",
       "      <th>categorie</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pour les galeries d’art, une situation moins s...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>economie</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quand la masturbation provoque une hémorragie ...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Les pistes de la France pour améliorer les ter...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>economie</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Facebook et Apple se livrent une guerre ouverte</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>economie</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Kent Walker : « Google agit selon les lois, et...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>pixels</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48445</th>\n",
       "      <td>160810</td>\n",
       "      <td>Covid-19 : la tentation du relâchement</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>checknews</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48446</th>\n",
       "      <td>160811</td>\n",
       "      <td>Mort d’Idriss Déby : le chaos va-t-il se rajou...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>moyen-orient</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48447</th>\n",
       "      <td>160812</td>\n",
       "      <td>Manchester City, Arsenal, Liverpool, Tottenham...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>football</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48448</th>\n",
       "      <td>160813</td>\n",
       "      <td>Derek Chauvin déclaré coupable du meurtre de G...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>amérique</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48449</th>\n",
       "      <td>160814</td>\n",
       "      <td>88% des exécutions recensées dans le monde ont...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>moyen-orient</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48450 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_article                                              titre  \\\n",
       "0               1  Pour les galeries d’art, une situation moins s...   \n",
       "1               2  Quand la masturbation provoque une hémorragie ...   \n",
       "2               3  Les pistes de la France pour améliorer les ter...   \n",
       "3               4    Facebook et Apple se livrent une guerre ouverte   \n",
       "4               5  Kent Walker : « Google agit selon les lois, et...   \n",
       "...           ...                                                ...   \n",
       "48445      160810             Covid-19 : la tentation du relâchement   \n",
       "48446      160811  Mort d’Idriss Déby : le chaos va-t-il se rajou...   \n",
       "48447      160812  Manchester City, Arsenal, Liverpool, Tottenham...   \n",
       "48448      160813  Derek Chauvin déclaré coupable du meurtre de G...   \n",
       "48449      160814  88% des exécutions recensées dans le monde ont...   \n",
       "\n",
       "      jour_publication     categorie     journal  \n",
       "0           2021-02-01      economie    Le Monde  \n",
       "1           2021-02-01      inconnue    Le Monde  \n",
       "2           2021-02-01      economie    Le Monde  \n",
       "3           2021-02-01      economie    Le Monde  \n",
       "4           2021-02-01        pixels    Le Monde  \n",
       "...                ...           ...         ...  \n",
       "48445       2021-04-20     checknews  Libération  \n",
       "48446       2021-04-20  moyen-orient  Libération  \n",
       "48447       2021-04-20      football  Libération  \n",
       "48448       2021-04-20      amérique  Libération  \n",
       "48449       2021-04-20  moyen-orient  Libération  \n",
       "\n",
       "[48450 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw, columns =[\"id_article\",\"titre\" ,\"jour_publication\" ,\"categorie\",\"journal\"  ])\n",
    "cursor.close()\n",
    "connection.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "société             6621\n",
       "international       5690\n",
       "economie            2884\n",
       "culture             2809\n",
       "monde               2781\n",
       "politique           2775\n",
       "people              2194\n",
       "idees               2125\n",
       "societe             1897\n",
       "planete             1644\n",
       "afrique             1535\n",
       "idées et débats     1151\n",
       "actualité           1141\n",
       "livres               893\n",
       "sport                848\n",
       "sciences             708\n",
       "m-le-mag             655\n",
       "santé                587\n",
       "inconnue             559\n",
       "checknews            544\n",
       "pixels               495\n",
       "royautes             446\n",
       "m-styles             433\n",
       "vecu                 380\n",
       "europe               380\n",
       "environnement        361\n",
       "disparitions         348\n",
       "sports               347\n",
       "les-decodeurs        312\n",
       "argent               306\n",
       "lifestyle            297\n",
       "m-perso              247\n",
       "amerique du nord     242\n",
       "musique              236\n",
       "campus               234\n",
       "emploi               193\n",
       "police-justice       189\n",
       "tribunes             177\n",
       "cinéma               140\n",
       "education            122\n",
       "Name: categorie, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.categorie.value_counts()[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.groupby('jour_publication'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération dans le package des stop-mots\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('french')\n",
    "stop_words.extend([\"c'est\",\"j'ai\",\"a\",\"plus\",\"contre\",\"après\", \"d'un\",\"d'une\",\"entre\",\"ans\",\"deux\",\"veut\",\"comme\",\n",
    "\"va\",\"trois\",\"sous\",\"faut\",\"n'est\",\"cinq\",\"leurs\",\"doit\",\"qu'il\",\"peut\",\"n'a\",\"mis\",\"six\",\"cette\",\"j'ai\",\"-\",\"s'est\",\"dit\",\"dont\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import FrenchStemmer #import utilisé pour raciniser les mots , finalement pas utilisé\n",
    "\n",
    "# fonction qui enlève les caractères spéciaux\n",
    "def nettoyage(text):\n",
    "    stemmer = FrenchStemmer()\n",
    "    text = str(text).lower() # mettre les mots en minuscule\n",
    "    text = re.sub(r\"[.,\\!\\?\\%\\(\\)\\/\\\"]\", \"\", text)  # Retrait les caractères spéciaux :\n",
    "    text = re.sub(r\"\\&\\S*\\s\", \"\", text)\n",
    "    text = re.sub(r\"\\d\", \"\", text) \n",
    "    text = re.sub(r\"\\-\", \"\", text) \n",
    "    text = re.sub(r\"\\:\", \"\", text)\n",
    "    text = re.sub(r\"\\»\", \"\", text) \n",
    "    text = re.sub(r\"\\«\", \"\", text)\n",
    "    text = re.sub(r\"\\’\", \" \", text)\n",
    "    text = text.split()\n",
    "    les_mots = \"\"\n",
    "    for mot in text:\n",
    "        a_ajouter = stemmer.stem(mot)\n",
    "        if a_ajouter not in stop_words:\n",
    "            les_mots = les_mots + \" \"+ a_ajouter\n",
    "    return les_mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_journal(x):\n",
    "        if x ==\"Le Monde\":\n",
    "            val = 1\n",
    "        elif x== \"Libération\":\n",
    "            val = 2\n",
    "        elif x ==\"L'Express\":\n",
    "            val = 3\n",
    "        elif x == \"Closer\":\n",
    "            val = 4\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.titre = df.titre.map(lambda x : nettoyage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_article</th>\n",
       "      <th>titre</th>\n",
       "      <th>jour_publication</th>\n",
       "      <th>categorie</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>galer art situat moin sombr redout</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>economie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>quand masturb provoqu hémorrag méning</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pist franc amélior term accord libreéchang me...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>economie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>facebook apple livrent guerr ouvert</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>economie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>kent walk googl agit selon lois non selon pol...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>pixels</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48445</th>\n",
       "      <td>160810</td>\n",
       "      <td>covid tentat relâch</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>checknews</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48446</th>\n",
       "      <td>160811</td>\n",
       "      <td>mort idriss déby chaos vatil rajout chaos</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>moyen-orient</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48447</th>\n",
       "      <td>160812</td>\n",
       "      <td>manchest city arsenal liverpool tottenham man...</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>football</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48448</th>\n",
       "      <td>160813</td>\n",
       "      <td>derek chauvin déclar coupabl meurtr georg floyd</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>amérique</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48449</th>\n",
       "      <td>160814</td>\n",
       "      <td>exécu recens dan mond lieu moyenorient</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>moyen-orient</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48450 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_article                                              titre  \\\n",
       "0               1                 galer art situat moin sombr redout   \n",
       "1               2              quand masturb provoqu hémorrag méning   \n",
       "2               3   pist franc amélior term accord libreéchang me...   \n",
       "3               4                facebook apple livrent guerr ouvert   \n",
       "4               5   kent walk googl agit selon lois non selon pol...   \n",
       "...           ...                                                ...   \n",
       "48445      160810                                covid tentat relâch   \n",
       "48446      160811          mort idriss déby chaos vatil rajout chaos   \n",
       "48447      160812   manchest city arsenal liverpool tottenham man...   \n",
       "48448      160813    derek chauvin déclar coupabl meurtr georg floyd   \n",
       "48449      160814             exécu recens dan mond lieu moyenorient   \n",
       "\n",
       "      jour_publication     categorie  journal  \n",
       "0           2021-02-01      economie        1  \n",
       "1           2021-02-01      inconnue        1  \n",
       "2           2021-02-01      economie        1  \n",
       "3           2021-02-01      economie        1  \n",
       "4           2021-02-01        pixels        1  \n",
       "...                ...           ...      ...  \n",
       "48445       2021-04-20     checknews        2  \n",
       "48446       2021-04-20  moyen-orient        2  \n",
       "48447       2021-04-20      football        2  \n",
       "48448       2021-04-20      amérique        2  \n",
       "48449       2021-04-20  moyen-orient        2  \n",
       "\n",
       "[48450 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.journal = df.journal.map(lambda x : encode_journal(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33915,) (14535,) (33915,) (14535,)\n"
     ]
    }
   ],
   "source": [
    "X = df.titre\n",
    "y = df['journal']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46472                  espac coworking aid étudi sort isol\n",
       "18460        karach rumeur accus mensonger dénonc balladur\n",
       "46806     téléthon pres million d'euros récolt malgr co...\n",
       "27180                  tchad grev enseign dan écol publiqu\n",
       "8201                                 non mort vot jo biden\n",
       "                               ...                        \n",
       "21243      environ futur del d'écocid seratil vrai efficac\n",
       "45891     jo suspens traval parc georgesvalbon premi ét...\n",
       "42613     offre menus végétarien étend dan cantin heurt...\n",
       "43567                                 givr gel hydroalcool\n",
       "2732      obtent démocrat égal sieg sénat géorg permett...\n",
       "Name: titre, Length: 33915, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15356\n",
       "2     8492\n",
       "3     7473\n",
       "4     2594\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6564\n",
       "2    3600\n",
       "3    3339\n",
       "4    1032\n",
       "Name: journal, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Sur-échantillonnage\n",
    "rOs = RandomOverSampler()\n",
    "X_ro, y_ro = rOs.fit_resample(np.array(X_train).reshape(-1,1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_ro.reshape(-1,)\n",
    "y_train = y_ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.25\n",
      "2    0.25\n",
      "3    0.25\n",
      "4    0.25\n",
      "Name: journal, dtype: float64\n",
      "1    0.451600\n",
      "2    0.247678\n",
      "3    0.229721\n",
      "4    0.071001\n",
      "Name: journal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts().apply(lambda x: x/len(y_train)))\n",
    "print(y_test.value_counts().apply(lambda x: x/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING Vectorisation et pondération"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "corpus = X_train.to_list()\n",
    "vectorizer.fit(corpus)\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary= vectorizer.get_feature_names())),\n",
    "                 ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "\n",
    "df_tfidf = pipe.transform(corpus).toarray()\n",
    "print(np.shape(df_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word')\n",
    "tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word_features = tfidf.transform(X_train)\n",
    "test_features = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22618\n"
     ]
    }
   ],
   "source": [
    "print(len(tfidf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61424, 22618)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_word_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Flask_journaux/src/models_pickle/file_tfidf.pkl' \n",
    "pickle.dump(tfidf, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Modèle KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix ,classification_report\n",
    "from sklearn.metrics import precision_score , recall_score, f1_score , r2_score , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/05/21 10:55:33 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "Accurancy 0.48434812521499826\n",
      "Precision 0.4836848299580491\n",
      "Recall 0.48434812521499826\n",
      "f1-score 0.48345566381233496\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Training KNN...\")\n",
    "    knn = KNeighborsClassifier()    \n",
    "    knn.fit(X_train_word_features, y_train)\n",
    "    pred_knn = knn.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_knn))\n",
    "    print('Precision', precision_score(y_test, pred_knn ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_knn,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_knn,average='weighted'))\n",
    "    mlflow.sklearn.log_model(knn,'KNN')\n",
    "    mlflow.log_param('algorithm','KNN')\n",
    "    mlflow.log_param('best_params',knn.get_params(deep=True))\n",
    "    mlflow.log_param('cross_val',cross_val_score(knn, X_train_word_features, y_train, cv=5))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_knn))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3647, 1590, 1136,  191],\n",
       "       [1462, 1487,  534,  117],\n",
       "       [1325,  714, 1202,   98],\n",
       "       [ 131,  117,   80,  704]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.56      0.56      6564\n",
      "           2       0.38      0.41      0.40      3600\n",
      "           3       0.41      0.36      0.38      3339\n",
      "           4       0.63      0.68      0.66      1032\n",
      "\n",
      "    accuracy                           0.48     14535\n",
      "   macro avg       0.49      0.50      0.50     14535\n",
      "weighted avg       0.48      0.48      0.48     14535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Flask_journaux/src/models_pickle/file_model_fitted_Knn.pkl' \n",
    "pickle.dump(knn, open(file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Modèle Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Randomforest...\n",
      "Accurancy 0.565875472996216\n",
      "Precision 0.5604511736785047\n",
      "Recall 0.565875472996216\n",
      "f1-score 0.5596065038146303\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Training Randomforest...\")\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train_word_features, y_train)\n",
    "    pred_rf = rf.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_rf))\n",
    "    print('Precision', precision_score(y_test, pred_rf ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_rf,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_rf,average='weighted'))\n",
    "    mlflow.sklearn.log_model(rf,'Random Forest')\n",
    "    mlflow.log_param('algorithm','RandomForest')\n",
    "    mlflow.log_param('best_params',rf.get_params(deep=True))\n",
    "    mlflow.log_param('cross_val',cross_val_score(rf, X_train_word_features, y_train, cv=5))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_rf))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_forest = RandomForestClassifier()\n",
    "n_estimators = [10,100,200]\n",
    "max_features = ['sqrt', 'log2']\n",
    "params_forest = dict(n_estimators = n_estimators, max_features = max_features)\n",
    "\n",
    "#model = RandomizedSearchCV(estimator = model_forest, param_distributions = param, n_jobs=-1, cv=6, scoring='f1',error_score=0)\n",
    "model = RandomForestClassifier(n_estimators = 10, max_features= 'sqrt', n_jobs=-1)\n",
    "model.fit(X_train_word_features, y_train)\n",
    "pred = model.predict(test_features)\n",
    "data = {'id_run':datetime.datetime.today() , 'model':str(model), 'hyperparameters':model.get_params(deep=True), 'f1':f1_score(y_test, pred,average='weighted')}\n",
    "with open('hyperparametres.txt', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1154,  768,  412,  204],\n",
       "       [ 388, 1523,  311,  152],\n",
       "       [ 507,  574,  998,  160],\n",
       "       [  75,  116,   37, 2349]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcul de la matrise de confusion \n",
    "confusion_matrix(y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.45      0.50      2538\n",
      "           2       0.51      0.64      0.57      2374\n",
      "           3       0.57      0.45      0.50      2239\n",
      "           4       0.82      0.91      0.86      2577\n",
      "\n",
      "    accuracy                           0.62      9728\n",
      "   macro avg       0.61      0.61      0.61      9728\n",
      "weighted avg       0.61      0.62      0.61      9728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. MODELE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accurancy 0.5893360853113175\n",
      "Precision 0.5841586537927693\n",
      "Recall 0.5893360853113175\n",
      "f1-score 0.5786601926828402\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"training SVM...\")\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train_word_features, y_train)\n",
    "    pred_svm = svm.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm))\n",
    "    print('Precision', precision_score(y_test, pred_svm ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_svm,average='weighted'))\n",
    "    mlflow.sklearn.log_model(svm,'SVM model')\n",
    "    mlflow.log_param('algorithm','SVM')\n",
    "    mlflow.log_param('best_params',svm.get_params(deep=True))\n",
    "    mlflow.log_param('cross_val',cross_val_score(svm, X_train_word_features, y_train, cv=5))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_svm))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Accurancy 0.6408305921052632\n",
      "Precision 0.6455588892625438\n",
      "Recall 0.6408305921052632\n",
      "f1-score 0.6408707013380684\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "# avec probability true  pour avoir les probas\n",
    "with mlflow.start_run():\n",
    "    print(\"training SVM...\")\n",
    "    svm = SVC(probability=True) \n",
    "    svm.fit(X_train_word_features, y_train)\n",
    "    pred_svm = svm.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm))\n",
    "    print('Precision', precision_score(y_test, pred_svm ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_svm,average='weighted'))\n",
    "    mlflow.sklearn.log_model(svm,'SVM model')\n",
    "    mlflow.log_param('algorithm','SVM')\n",
    "    mlflow.log_param('best_params',svm.get_params(deep=True))\n",
    "    #mlflow.log_param('cross_val',cross_val_score(svm, X_train_word_features, y_train, cv=5))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_svm,average='weighted'))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.83300759e-03, 4.04580142e-03, 6.63743919e-03, 9.85483752e-01],\n",
       "       [4.84986786e-09, 5.52340215e-09, 3.45009503e-09, 9.99999986e-01],\n",
       "       [6.92627957e-01, 1.81541323e-01, 1.25049384e-01, 7.81336424e-04],\n",
       "       ...,\n",
       "       [2.87580736e-01, 2.85483834e-01, 3.95250031e-01, 3.16853979e-02],\n",
       "       [2.62916533e-01, 2.00245395e-01, 5.32837338e-01, 4.00073289e-03],\n",
       "       [3.20500886e-01, 3.56217833e-01, 3.01747443e-01, 2.15338379e-02]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1500,  594,  374,   70],\n",
       "       [ 697, 1296,  317,   64],\n",
       "       [ 675,  426, 1075,   63],\n",
       "       [  95,   83,   36, 2363]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.59      0.54      2538\n",
      "           2       0.54      0.55      0.54      2374\n",
      "           3       0.60      0.48      0.53      2239\n",
      "           4       0.92      0.92      0.92      2577\n",
      "\n",
      "    accuracy                           0.64      9728\n",
      "   macro avg       0.64      0.63      0.64      9728\n",
      "weighted avg       0.65      0.64      0.64      9728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. MODELE NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Naive bayes...\n",
      "Accurancy 0.5136838314728124\n",
      "Precision 0.5117851979488818\n",
      "Recall 0.5136838314728124\n",
      "f1-score 0.5023671774103569\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"training Naive bayes...\")\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_word_features.toarray(), y_train)\n",
    "    pred_mnb = mnb.predict(test_features.toarray())\n",
    "    print('Accurancy', accuracy_score(y_test, pred_mnb))\n",
    "    print('Precision', precision_score(y_test, pred_mnb ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_mnb,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_mnb,average='weighted'))\n",
    "    mlflow.sklearn.log_model(mnb,'Naive_bayes')\n",
    "    mlflow.log_param('algorithm','Naive_bayes')\n",
    "    mlflow.log_param('best_params',mnb.get_params(deep=True))\n",
    "    mlflow.log_param('cross_val',cross_val_score(mnb, X_train_word_features, y_train, cv=5))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_mnb))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1566,  343,  457,  172],\n",
       "       [ 877,  847,  422,  228],\n",
       "       [ 728,  260, 1111,  140],\n",
       "       [  67,   19,   30, 2461]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.62      0.54      2538\n",
      "           2       0.58      0.36      0.44      2374\n",
      "           3       0.55      0.50      0.52      2239\n",
      "           4       0.82      0.95      0.88      2577\n",
      "\n",
      "    accuracy                           0.62      9728\n",
      "   macro avg       0.61      0.61      0.60      9728\n",
      "weighted avg       0.61      0.62      0.60      9728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Hyperparamètres & Modèle KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning KNN...\n",
      "Best: 0.794781 using {'weights': 'distance', 'n_neighbors': 7, 'metric': 'euclidean'}\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "# recherche via randomsied serach knn\n",
    "with mlflow.start_run():\n",
    "    print(\"Tuning KNN...\")\n",
    "    knn = KNeighborsClassifier()\n",
    "    n_neighbors = range(1, 21, 2)\n",
    "    weights = ['uniform', 'distance']\n",
    "    metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "\n",
    "    # define grid search\n",
    "    params_knn = dict(n_neighbors = n_neighbors , weights = weights, metric = metric)\n",
    "    #cv_knn = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_knn = RandomizedSearchCV(estimator=knn, param_distributions = params_knn, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    random_result_knn = random_search_knn.fit(X_train_word_features, y_train)\n",
    "\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (random_result_knn.best_score_, random_result_knn.best_params_))\n",
    "    mlflow.sklearn.log_model(KNeighborsClassifier(), \"journaux\")\n",
    "    mlflow.log_param('algorithm','KNN randomisedSearch')\n",
    "    mlflow.log_param('best_params',random_result_knn.best_params_)\n",
    "    mlflow.log_metric(\"best_score\", random_result_knn.best_score_)\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrainement du meilleur set d'hyperparamètres KNN\n",
    "with mlflow.start_run():\n",
    "    print(\"Traning best model Knn...\")\n",
    "    knn_opti = KNeighborsClassifier(n_neighbors = 15 , weights = 'distance', metric ='euclidean')\n",
    "    #scores_cross_val_knn= cross_val_score(knn_opti,X_train_word_features,y_train, cv=5 )\n",
    "    knn_opti.fit(X_train_word_features, y_train)\n",
    "    pred_knn_opti = knn_opti.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_knn_opti))\n",
    "    print('Precision', precision_score(y_test, pred_knn_opti ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_knn_opti,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_knn_opti,average='weighted'))\n",
    "    mlflow.log_param('best_params',knn_opti.get_params(deep=True))\n",
    "    mlflow.log_metric(\"score\", accuracy_score(y_test, pred_knn_opti,average='weighted'))\n",
    "    mlflow.sklearn.log_model(KNeighborsClassifier(), \"journaux\")\n",
    "    #mlflow.log_param('cross_val',scores_cross_val_knn)\n",
    "    mlflow.log_param('algorithm','KNN tuned')\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_knn = 'Flask_journaux/src/models_pickle/file_model_fitted_knn_opti.pkl' \n",
    "pickle.dump(knn_opti, open(file_knn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Hyperparamètres & Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recherche meilleur set hyperparamètres RandonForest\n",
    "with mlflow.start_run():\n",
    "    print(\"Tuning Randomforest...\")\n",
    "    model_forest = RandomForestClassifier()\n",
    "    n_estimators = [10,100,200]\n",
    "    max_features = ['sqrt', 'log2']\n",
    "    params_forest = dict(n_estimators = n_estimators, max_features = max_features)\n",
    "    #cv_forest = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_forest = RandomizedSearchCV(estimator = model_forest, param_distributions = params_forest, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    random_result_forest = random_search_forest.fit(X_train_word_features, y_train)\n",
    "    print(\"Best: %f using %s\" % (random_result_forest.best_score_, random_result_forest.best_params_))\n",
    "    mlflow.log_param('best_params',random_result_forest.best_params_)\n",
    "    mlflow.log_metric(\"best_score\", random_result_forest.best_score_)\n",
    "    mlflow.sklearn.log_model(RandomForestClassifier(), \"journaux\")\n",
    "    mlflow.log_param('algorithm', 'RandomForest randomisedSearch')\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best model Randomforest...\n",
      "Accurancy 0.5823185414516684\n",
      "Precision 0.5821308944016204\n",
      "Recall 0.5823185414516684\n",
      "f1-score 0.576203170576184\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "accuracy_score() got an unexpected keyword argument 'average'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-f1d731f4330b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1-score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_rf_opti\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_params'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_opti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_rf_opti\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"journaux\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'algorithm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RandomForest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: accuracy_score() got an unexpected keyword argument 'average'"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Training best model Randomforest...\")\n",
    "    rf_opti = RandomForestClassifier(n_estimators=200,max_features='log2')\n",
    "    #scores_cross_val_rf= cross_val_score(rf_opti,X_train_word_features, y_train, cv=5)\n",
    "    rf_opti.fit(X_train_word_features, y_train)\n",
    "    pred_rf_opti = rf_opti.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    print('Precision', precision_score(y_test, pred_rf_opti ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    mlflow.log_param('best_params',rf_opti.get_params())\n",
    "    mlflow.log_metric(\"score\", accuracy_score(y_test, pred_rf_opti,average='weighted'))\n",
    "    mlflow.sklearn.log_model(RandomForestClassifier(), \"journaux\")\n",
    "    mlflow.log_param('algorithm', 'RandomForest')\n",
    "    #mlflow.log_param('cross_val',scores_cross_val_rf)\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = rf_opti.score(y_test,pred_rf_opti)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(4):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve ,auc\n",
    "fpr, tpr, threshold = roc_curve(y_test,pred_rf_opti)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rf = 'Flask_journaux/src/models_pickle/file_model_fitted_RandonForest_opti.pkl' \n",
    "pickle.dump(rf_opti, open(file_rf, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.3. Hyperparamètres & MODELE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    print(\"Tuning SVM...\")\n",
    "    svm = SVC()\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    C = [50, 10, 1.0, 0.1, 0.01]\n",
    "    gamma = ['scale']\n",
    "    # define grid search\n",
    "    params_svm = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "    #cv_svm = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_SVM = RandomizedSearchCV(estimator=svm, param_distributions=params_svm, n_jobs=-1, cv=5, scoring='accuracy',error_score=0)\n",
    "    random_result_SVM = random_search_SVM.fit(X_train_word_features, y_train)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (random_result_SVM.best_score_, random_result_SVM.best_params_))\n",
    "    mlflow.log_param('best_params',random_result_SVM.best_params_)\n",
    "    mlflow.log_param('algorithm','SVM randomizedSearchCV')\n",
    "    mlflow.log_metric(\"best_score\", random_result_SVM.best_score_)\n",
    "    mlflow.sklearn.log_model(SVC(), \"journaux\")\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n",
      "Best: 0.631419 using {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "# copie de la cellule du haut\n",
    "with mlflow.start_run(nested=True):\n",
    "    print(\"Tuning SVM...\")\n",
    "    svm = SVC()\n",
    "    kernel = ['poly', 'rbf', 'sigmoid']\n",
    "    C = [50, 10, 1.0, 0.1, 0.01]\n",
    "    gamma = ['scale']\n",
    "    # define grid search\n",
    "    params_svm = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "    cv_svm = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    random_search_SVM = RandomizedSearchCV(estimator=svm, param_distributions=params_svm, n_jobs=-1, cv=cv_svm, scoring='accuracy',error_score=0)\n",
    "    random_result_SVM = random_search_SVM.fit(X_train_word_features, y_train)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (random_result_SVM.best_score_, random_result_SVM.best_params_))\n",
    "    mlflow.log_param('best_params',random_result_SVM.best_params_)\n",
    "    mlflow.log_param('algorithm','SVM randomizedSearchCV')\n",
    "    mlflow.log_metric(\"best_score\", random_result_SVM.best_score_)\n",
    "    mlflow.sklearn.log_model(SVC(), \"journaux\")\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([322.18364176, 117.40339882, 333.18399922, 157.41959755,\n",
       "        123.95367841, 110.03318853,  84.28457875, 234.59466761,\n",
       "        289.0349294 , 118.2553923 ]),\n",
       " 'std_fit_time': array([ 5.11694405,  2.16924064, 10.25318381,  6.4141064 ,  2.89853473,\n",
       "         2.72571445,  2.24538314, 34.18457842,  6.35135466,  3.76527422]),\n",
       " 'mean_score_time': array([7.04833902, 7.18716965, 7.24186418, 6.54423445, 7.03660782,\n",
       "        6.84834101, 5.74491012, 4.65829961, 6.20478531, 6.44726063]),\n",
       " 'std_score_time': array([0.17337761, 0.25275243, 0.31525551, 0.47020058, 0.35000543,\n",
       "        0.24229602, 0.24193113, 0.23462313, 0.12098137, 0.86298897]),\n",
       " 'param_kernel': masked_array(data=['poly', 'poly', 'poly', 'rbf', 'rbf', 'sigmoid',\n",
       "                    'sigmoid', 'sigmoid', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=['scale', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'scale', 'scale'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_C': masked_array(data=[10, 0.1, 50, 1.0, 0.1, 0.1, 1.0, 10, 10, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'kernel': 'poly', 'gamma': 'scale', 'C': 10},\n",
       "  {'kernel': 'poly', 'gamma': 'scale', 'C': 0.1},\n",
       "  {'kernel': 'poly', 'gamma': 'scale', 'C': 50},\n",
       "  {'kernel': 'rbf', 'gamma': 'scale', 'C': 1.0},\n",
       "  {'kernel': 'rbf', 'gamma': 'scale', 'C': 0.1},\n",
       "  {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 0.1},\n",
       "  {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 1.0},\n",
       "  {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 10},\n",
       "  {'kernel': 'rbf', 'gamma': 'scale', 'C': 10},\n",
       "  {'kernel': 'rbf', 'gamma': 'scale', 'C': 0.01}],\n",
       " 'split0_test_score': array([0.59162996, 0.26740088, 0.59162996, 0.62907489, 0.45374449,\n",
       "        0.51277533, 0.62907489, 0.57488987, 0.63612335, 0.26299559]),\n",
       " 'split1_test_score': array([0.61718062, 0.26872247, 0.61718062, 0.65903084, 0.46211454,\n",
       "        0.53700441, 0.64405286, 0.61409692, 0.66343612, 0.26299559]),\n",
       " 'split2_test_score': array([0.58193833, 0.26299559, 0.5814978 , 0.63303965, 0.45594714,\n",
       "        0.5215859 , 0.62378855, 0.59867841, 0.64405286, 0.26255507]),\n",
       " 'split3_test_score': array([0.58590308, 0.26475771, 0.58590308, 0.62863436, 0.44581498,\n",
       "        0.51674009, 0.62731278, 0.6       , 0.64008811, 0.26255507]),\n",
       " 'split4_test_score': array([0.58634361, 0.26475771, 0.58634361, 0.63127753, 0.43656388,\n",
       "        0.50881057, 0.61629956, 0.5814978 , 0.6339207 , 0.26255507]),\n",
       " 'split5_test_score': array([0.58546256, 0.26431718, 0.58502203, 0.62511013, 0.45594714,\n",
       "        0.51409692, 0.61762115, 0.58634361, 0.63744493, 0.26255507]),\n",
       " 'split6_test_score': array([0.57709251, 0.2660793 , 0.57709251, 0.61585903, 0.44581498,\n",
       "        0.52599119, 0.61321586, 0.57092511, 0.62114537, 0.26255507]),\n",
       " 'split7_test_score': array([0.60643455, 0.26443367, 0.60643455, 0.62979286, 0.45085941,\n",
       "        0.51784927, 0.62141913, 0.58439841, 0.63331864, 0.26267078]),\n",
       " 'split8_test_score': array([0.56148083, 0.26443367, 0.56192155, 0.6112825 , 0.44909652,\n",
       "        0.52401939, 0.61480829, 0.57955046, 0.60687528, 0.26267078]),\n",
       " 'split9_test_score': array([0.5879242 , 0.26487439, 0.5879242 , 0.6209784 , 0.45306302,\n",
       "        0.50594976, 0.61040106, 0.57426179, 0.62538563, 0.26267078]),\n",
       " 'split10_test_score': array([0.60176211, 0.26740088, 0.60176211, 0.65022026, 0.46211454,\n",
       "        0.52334802, 0.64317181, 0.59603524, 0.64977974, 0.26299559]),\n",
       " 'split11_test_score': array([0.58237885, 0.26563877, 0.58237885, 0.62202643, 0.44361233,\n",
       "        0.52202643, 0.62246696, 0.60044053, 0.6246696 , 0.26299559]),\n",
       " 'split12_test_score': array([0.57488987, 0.2660793 , 0.57488987, 0.61674009, 0.45242291,\n",
       "        0.51321586, 0.61629956, 0.58942731, 0.61982379, 0.26255507]),\n",
       " 'split13_test_score': array([0.59427313, 0.26431718, 0.59471366, 0.62951542, 0.45682819,\n",
       "        0.52290749, 0.62334802, 0.58325991, 0.63171806, 0.26255507]),\n",
       " 'split14_test_score': array([0.57180617, 0.26563877, 0.5722467 , 0.61938326, 0.45374449,\n",
       "        0.51629956, 0.61277533, 0.57797357, 0.62422907, 0.26255507]),\n",
       " 'split15_test_score': array([0.57621145, 0.26387665, 0.57621145, 0.62334802, 0.44052863,\n",
       "        0.50792952, 0.61101322, 0.5876652 , 0.62246696, 0.26255507]),\n",
       " 'split16_test_score': array([0.60220264, 0.26519824, 0.60220264, 0.62951542, 0.44185022,\n",
       "        0.5215859 , 0.62202643, 0.57709251, 0.6277533 , 0.26255507]),\n",
       " 'split17_test_score': array([0.57910974, 0.26443367, 0.57910974, 0.62406346, 0.44909652,\n",
       "        0.51608638, 0.61524901, 0.58395769, 0.62230057, 0.26267078]),\n",
       " 'split18_test_score': array([0.57999119, 0.26531512, 0.57955046, 0.62494491, 0.45702953,\n",
       "        0.51520494, 0.61745262, 0.57999119, 0.6267078 , 0.26267078]),\n",
       " 'split19_test_score': array([0.59453504, 0.26487439, 0.59541648, 0.6324372 , 0.44645218,\n",
       "        0.51961216, 0.62847069, 0.58572058, 0.63860732, 0.26267078]),\n",
       " 'split20_test_score': array([0.58281938, 0.26431718, 0.58370044, 0.630837  , 0.44581498,\n",
       "        0.51674009, 0.61806167, 0.58061674, 0.63171806, 0.26299559]),\n",
       " 'split21_test_score': array([0.59911894, 0.2660793 , 0.59911894, 0.63568282, 0.45418502,\n",
       "        0.51982379, 0.63524229, 0.58898678, 0.64845815, 0.26299559]),\n",
       " 'split22_test_score': array([0.5722467 , 0.26696035, 0.5722467 , 0.61762115, 0.45022026,\n",
       "        0.50881057, 0.60969163, 0.57929515, 0.61629956, 0.26255507]),\n",
       " 'split23_test_score': array([0.59427313, 0.26431718, 0.59471366, 0.62643172, 0.44845815,\n",
       "        0.51585903, 0.61409692, 0.57797357, 0.62643172, 0.26255507]),\n",
       " 'split24_test_score': array([0.58237885, 0.26475771, 0.58237885, 0.62114537, 0.45154185,\n",
       "        0.51629956, 0.62422907, 0.5845815 , 0.62599119, 0.26255507]),\n",
       " 'split25_test_score': array([0.58898678, 0.2660793 , 0.58898678, 0.63127753, 0.45859031,\n",
       "        0.52422907, 0.62951542, 0.5969163 , 0.63656388, 0.26255507]),\n",
       " 'split26_test_score': array([0.58590308, 0.26696035, 0.58546256, 0.63788546, 0.45242291,\n",
       "        0.52643172, 0.63480176, 0.60396476, 0.64185022, 0.26255507]),\n",
       " 'split27_test_score': array([0.58704275, 0.26443367, 0.58748347, 0.61613045, 0.45570736,\n",
       "        0.51917144, 0.60687528, 0.57382107, 0.62318202, 0.26267078]),\n",
       " 'split28_test_score': array([0.57822829, 0.26487439, 0.57822829, 0.62406346, 0.44601146,\n",
       "        0.51035699, 0.61745262, 0.58043191, 0.62802997, 0.26267078]),\n",
       " 'split29_test_score': array([0.57778757, 0.26399295, 0.57690613, 0.62230057, 0.4468929 ,\n",
       "        0.51740855, 0.6170119 , 0.58043191, 0.63420009, 0.26267078]),\n",
       " 'mean_test_score': array([0.58624453, 0.26527726, 0.58628859, 0.62732167, 0.45074969,\n",
       "        0.517939  , 0.62124154, 0.58577419, 0.63141907, 0.26267789]),\n",
       " 'std_test_score': array([0.01137441, 0.00123887, 0.01140091, 0.00965632, 0.00603272,\n",
       "        0.00642312, 0.0092505 , 0.01002427, 0.0110871 , 0.00016657]),\n",
       " 'rank_test_score': array([ 5,  9,  4,  2,  8,  7,  3,  6,  1, 10])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# donne les valeurs des hyperparametres et le score ici accuracy\n",
    "a_enregistrer = random_result_SVM.cv_results_\n",
    "a_enregistrer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kernel': 'poly', 'gamma': 'scale', 'C': 10},\n",
       " {'kernel': 'poly', 'gamma': 'scale', 'C': 0.1},\n",
       " {'kernel': 'poly', 'gamma': 'scale', 'C': 50},\n",
       " {'kernel': 'rbf', 'gamma': 'scale', 'C': 1.0},\n",
       " {'kernel': 'rbf', 'gamma': 'scale', 'C': 0.1},\n",
       " {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 0.1},\n",
       " {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 1.0},\n",
       " {'kernel': 'sigmoid', 'gamma': 'scale', 'C': 10},\n",
       " {'kernel': 'rbf', 'gamma': 'scale', 'C': 10},\n",
       " {'kernel': 'rbf', 'gamma': 'scale', 'C': 0.01}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a_enregistrer['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5862445306043468,\n",
       " 0.2652772638169182,\n",
       " 0.5862885899394831,\n",
       " 0.6273216739182068,\n",
       " 0.45074969469754184,\n",
       " 0.5179389964593328,\n",
       " 0.6212415439146927,\n",
       " 0.5857741933187461,\n",
       " 0.6314190691235828,\n",
       " 0.26267788600617786]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a_enregistrer['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_estimator': 'SVC()',\n",
       "  'kernel': 'poly',\n",
       "  'gamma': 'scale',\n",
       "  'C': 10,\n",
       "  'mean_test_score': 0.5862445306043468,\n",
       "  'std_test_score': 0.011374414831231631},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'poly',\n",
       "  'gamma': 'scale',\n",
       "  'C': 0.1,\n",
       "  'mean_test_score': 0.2652772638169182,\n",
       "  'std_test_score': 0.0012388719650589292},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'poly',\n",
       "  'gamma': 'scale',\n",
       "  'C': 50,\n",
       "  'mean_test_score': 0.5862885899394831,\n",
       "  'std_test_score': 0.01140091322413865},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'rbf',\n",
       "  'gamma': 'scale',\n",
       "  'C': 1.0,\n",
       "  'mean_test_score': 0.6273216739182068,\n",
       "  'std_test_score': 0.009656317967873359},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'rbf',\n",
       "  'gamma': 'scale',\n",
       "  'C': 0.1,\n",
       "  'mean_test_score': 0.45074969469754184,\n",
       "  'std_test_score': 0.006032715820608887},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'sigmoid',\n",
       "  'gamma': 'scale',\n",
       "  'C': 0.1,\n",
       "  'mean_test_score': 0.5179389964593328,\n",
       "  'std_test_score': 0.006423115715018225},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'sigmoid',\n",
       "  'gamma': 'scale',\n",
       "  'C': 1.0,\n",
       "  'mean_test_score': 0.6212415439146927,\n",
       "  'std_test_score': 0.009250503275448546},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'sigmoid',\n",
       "  'gamma': 'scale',\n",
       "  'C': 10,\n",
       "  'mean_test_score': 0.5857741933187461,\n",
       "  'std_test_score': 0.010024268699033183},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'rbf',\n",
       "  'gamma': 'scale',\n",
       "  'C': 10,\n",
       "  'mean_test_score': 0.6314190691235828,\n",
       "  'std_test_score': 0.011087098588097685},\n",
       " {'model_estimator': 'SVC()',\n",
       "  'kernel': 'rbf',\n",
       "  'gamma': 'scale',\n",
       "  'C': 0.01,\n",
       "  'mean_test_score': 0.26267788600617786,\n",
       "  'std_test_score': 0.00016656914492242452}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_list = len(a_enregistrer['params'])\n",
    "list =[]\n",
    "for i in range(long_list):\n",
    "    list.append(dict( {'model_estimator':str(random_result_SVM.estimator),'kernel':a_enregistrer['params'][i]['kernel'], 'gamma':a_enregistrer['params'][i]['gamma'], 'C' : a_enregistrer['params'][i]['C'], 'mean_test_score': a_enregistrer['mean_test_score'][i], 'std_test_score':a_enregistrer['std_test_score'][i]}))\n",
    "    \n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"model_estimator\": \"SVC()\", \"kernel\": \"poly\", \"gamma\": \"scale\", \"C\": 10, \"mean_test_score\": 0.5862445306043468, \"std_test_score\": 0.011374414831231631}, {\"model_estimator\": \"SVC()\", \"kernel\": \"poly\", \"gamma\": \"scale\", \"C\": 0.1, \"mean_test_score\": 0.2652772638169182, \"std_test_score\": 0.0012388719650589292}, {\"model_estimator\": \"SVC()\", \"kernel\": \"poly\", \"gamma\": \"scale\", \"C\": 50, \"mean_test_score\": 0.5862885899394831, \"std_test_score\": 0.01140091322413865}, {\"model_estimator\": \"SVC()\", \"kernel\": \"rbf\", \"gamma\": \"scale\", \"C\": 1.0, \"mean_test_score\": 0.6273216739182068, \"std_test_score\": 0.009656317967873359}, {\"model_estimator\": \"SVC()\", \"kernel\": \"rbf\", \"gamma\": \"scale\", \"C\": 0.1, \"mean_test_score\": 0.45074969469754184, \"std_test_score\": 0.006032715820608887}, {\"model_estimator\": \"SVC()\", \"kernel\": \"sigmoid\", \"gamma\": \"scale\", \"C\": 0.1, \"mean_test_score\": 0.5179389964593328, \"std_test_score\": 0.006423115715018225}, {\"model_estimator\": \"SVC()\", \"kernel\": \"sigmoid\", \"gamma\": \"scale\", \"C\": 1.0, \"mean_test_score\": 0.6212415439146927, \"std_test_score\": 0.009250503275448546}, {\"model_estimator\": \"SVC()\", \"kernel\": \"sigmoid\", \"gamma\": \"scale\", \"C\": 10, \"mean_test_score\": 0.5857741933187461, \"std_test_score\": 0.010024268699033183}, {\"model_estimator\": \"SVC()\", \"kernel\": \"rbf\", \"gamma\": \"scale\", \"C\": 10, \"mean_test_score\": 0.6314190691235828, \"std_test_score\": 0.011087098588097685}, {\"model_estimator\": \"SVC()\", \"kernel\": \"rbf\", \"gamma\": \"scale\", \"C\": 0.01, \"mean_test_score\": 0.26267788600617786, \"std_test_score\": 0.00016656914492242452}]'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formater en json\n",
    "import json\n",
    "json_formate = json.dumps(list)\n",
    "json_formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer dans un json\n",
    "with open('monitoring_randomsearch.json', 'w') as f:\n",
    "    json.dump(list,f,indent=4, ensure_ascii=False, sort_keys=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_estimator': 'SVC()', 'kernel': 'poly', 'gamma': 'scale', 'C': 10, 'mean_test_score': 0.5862445306043468, 'std_test_score': 0.011374414831231631}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'poly', 'gamma': 'scale', 'C': 0.1, 'mean_test_score': 0.2652772638169182, 'std_test_score': 0.0012388719650589292}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'poly', 'gamma': 'scale', 'C': 50, 'mean_test_score': 0.5862885899394831, 'std_test_score': 0.01140091322413865}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'rbf', 'gamma': 'scale', 'C': 1.0, 'mean_test_score': 0.6273216739182068, 'std_test_score': 0.009656317967873359}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'rbf', 'gamma': 'scale', 'C': 0.1, 'mean_test_score': 0.45074969469754184, 'std_test_score': 0.006032715820608887}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'sigmoid', 'gamma': 'scale', 'C': 0.1, 'mean_test_score': 0.5179389964593328, 'std_test_score': 0.006423115715018225}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'sigmoid', 'gamma': 'scale', 'C': 1.0, 'mean_test_score': 0.6212415439146927, 'std_test_score': 0.009250503275448546}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'sigmoid', 'gamma': 'scale', 'C': 10, 'mean_test_score': 0.5857741933187461, 'std_test_score': 0.010024268699033183}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'rbf', 'gamma': 'scale', 'C': 10, 'mean_test_score': 0.6314190691235828, 'std_test_score': 0.011087098588097685}\n",
      "{'model_estimator': 'SVC()', 'kernel': 'rbf', 'gamma': 'scale', 'C': 0.01, 'mean_test_score': 0.26267788600617786, 'std_test_score': 0.00016656914492242452}\n"
     ]
    }
   ],
   "source": [
    "# load un json\n",
    "with open('monitoring_randomsearch.json') as f:\n",
    "      data = json.load(f)\n",
    "for model in data:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best model SVM...\n",
      "Accurancy 0.5902992776057792\n",
      "Precision 0.5869194051648337\n",
      "Recall 0.5902992776057792\n",
      "f1-score 0.5785092571432933\n",
      "Fin de traitement\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du Modèle optimisé \n",
    "# on doit mettre probability true sinon pas de prédict_proba possible\n",
    "with mlflow.start_run():\n",
    "    print(\"Training best model SVM...\")\n",
    "    svm_opti = SVC(kernel = 'rbf', C = 50, gamma = 'scale', probability=True)\n",
    "    svm_opti.fit(X_train_word_features, y_train)\n",
    "    pred_svm_opti = svm_opti.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm_opti))\n",
    "    print('Precision', precision_score(y_test, pred_svm_opti ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm_opti,average='weighted'))\n",
    "    print('f1-score', f1_score(y_test, pred_svm_opti,average='weighted'))\n",
    "    #mlflow.sklearn.log_model(svm_opti,'SVM model')\n",
    "    mlflow.log_param('algorithm','SVM')\n",
    "    mlflow.log_param('best_params',svm_opti.get_params(deep=True))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_svm_opti))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_svm = 'Flask_journaux/src/models_pickle/file_model_fitted_svm_opti.pkl' \n",
    "pickle.dump(svm_opti, open(file_svm, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.63609685e-03, 2.71810098e-03, 4.42679652e-03, 9.90219006e-01],\n",
       "       [1.69418947e-09, 1.85433148e-09, 1.29252219e-09, 9.99999995e-01],\n",
       "       [6.27080273e-01, 2.18299612e-01, 1.53416654e-01, 1.20346051e-03],\n",
       "       ...,\n",
       "       [2.24346529e-01, 2.29862850e-01, 5.26154335e-01, 1.96362863e-02],\n",
       "       [2.31603344e-01, 1.83895678e-01, 5.82938564e-01, 1.56241365e-03],\n",
       "       [3.31237601e-01, 3.12897855e-01, 3.37799981e-01, 1.80645635e-02]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_opti.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.77      0.67      6564\n",
      "           2       0.52      0.40      0.45      3600\n",
      "           3       0.55      0.40      0.46      3339\n",
      "           4       0.89      0.73      0.80      1032\n",
      "\n",
      "    accuracy                           0.59     14535\n",
      "   macro avg       0.64      0.57      0.60     14535\n",
      "weighted avg       0.59      0.59      0.58     14535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_svm_opti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best model SVM...\n"
     ]
    }
   ],
   "source": [
    "# Modèle optimisé 2\n",
    "with mlflow.start_run():\n",
    "    print(\"Training best model SVM...\")\n",
    "    svm_opti2 = SVC(kernel = 'rbf', C = 10, gamma = 'scale',probability=True)\n",
    "    svm_opti2.fit(X_train_word_features, y_train)\n",
    "    pred_svm_opti2 = svm_opti2.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm_opti2))\n",
    "    print('Precision', precision_score(y_test, pred_svm_opti2 ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm_opti2,average='weighted'))\n",
    "    print('f1-score', accuracy_score(y_test, pred_svm_opti2))\n",
    "    mlflow.sklearn.log_model(svm_opti2,'SVM model')\n",
    "    mlflow.log_param('algorithm','SVM')\n",
    "    mlflow.log_param('best_params',svm_opti2.get_params(deep=True))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_svm_opti2))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_svm = 'Flask_journaux/src/models_pickle/file_model_fitted_svm_opti2.pkl' \n",
    "pickle.dump(svm_opti2, open(file_svm, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle optimisé 3\n",
    "with mlflow.start_run():\n",
    "    print(\"Training best model SVM...\")\n",
    "    svm_opti3 = SVC(kernel = 'rbf', C = 1.0, gamma = 'scale',probability=True)\n",
    "    svm_opti3.fit(X_train_word_features, y_train)\n",
    "    pred_svm_opti3 = svm_opti3.predict(test_features)\n",
    "    print('Accurancy', accuracy_score(y_test, pred_svm_opti3))\n",
    "    print('Precision', precision_score(y_test, pred_svm_opti3 ,average='weighted'))\n",
    "    print('Recall', recall_score(y_test, pred_svm_opti3,average='weighted'))\n",
    "    print('f1-score', accuracy_score(y_test, pred_svm_opti3))\n",
    "    mlflow.sklearn.log_model(svm,'SVM model')\n",
    "    mlflow.log_param('algorithm','SVM')\n",
    "    mlflow.log_param('best_params',svm_opti3.get_params(deep=True))\n",
    "    mlflow.log_metric(\"score\",accuracy_score(y_test, pred_svm_opti3))\n",
    "    print(\"Fin de traitement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_svm = 'Flask_journaux/src/models_pickle/file_model_fitted_svm_opti3.pkl' \n",
    "pickle.dump(svm_opti3, open(file_svm, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning Naive bayes seul le parametres var_smoothing peut etre tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62312775 0.6246696  0.63053536 0.62392597 0.63207755]\n",
      "cv_scoresopti mean:0.6268672484090404\n",
      "[0.62334802 0.62378855 0.6294338  0.62480723 0.6311963 ]\n",
      "cv_scoresopti2 mean:0.6265147769744932\n",
      "[0.6154185  0.61740088 0.6311963  0.61885878 0.63141661]\n",
      "cv_scoresopti3 mean:0.6228582146118854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scoresopti = cross_val_score(svm_opti, X_train_word_features, y_train, cv=5)\n",
    "cv_scoresopti2 = cross_val_score(svm_opti2, X_train_word_features, y_train, cv=5)\n",
    "cv_scoresopti3 = cross_val_score(svm_opti3, X_train_word_features, y_train, cv=5)\n",
    "\n",
    "print(cv_scoresopti)\n",
    "print(\"cv_scoresopti mean:{}\".format(np.mean(cv_scoresopti)))\n",
    "print(cv_scoresopti2)\n",
    "print(\"cv_scoresopti2 mean:{}\".format(np.mean(cv_scoresopti2)))\n",
    "print(cv_scoresopti3)\n",
    "print(\"cv_scoresopti3 mean:{}\".format(np.mean(cv_scoresopti3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 = knn6.fit(X_train_word_features, y_train)\n",
    "\n",
    "file6 = 'Flask_journaux/src/models_pickle/file_model_fitted_Knn6.pkl' \n",
    "pickle.dump(results6, open(file6, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results19 = knn19.fit(X_train_word_features, y_train)\n",
    "\n",
    "file19 = 'Flask_journaux/src/models_pickle/file_model_fitted_Knn19.pkl' \n",
    "pickle.dump(results19, open(file19, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat6 = results6.predict(test_features)\n",
    "y_hat_proba6 = results6.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat19 = results19.predict(test_features)\n",
    "y_hat_proba19 = results19.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1082,  714,  185,  332,   73],\n",
       "       [ 624, 1194,  182,  310,  107],\n",
       "       [ 420,  504, 1005,  240,   71],\n",
       "       [ 599,  560,  235,  760,   64],\n",
       "       [  90,  171,   69,   60, 2144]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 962,  699,  214,  394,  117],\n",
       "       [ 520, 1161,  206,  356,  174],\n",
       "       [ 325,  498, 1034,  273,  110],\n",
       "       [ 447,  571,  225,  878,   97],\n",
       "       [  54,  134,   49,   50, 2247]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy6 0.5243747350572276\n",
      "Precision 0.5407635311686833\n",
      "Recall 0.5243747350572276\n",
      "f1-score 0.5270738032755025\n"
     ]
    }
   ],
   "source": [
    "print('Accurancy6', accuracy_score(y_test, y_hat6))\n",
    "print('Precision', precision_score(y_test, y_hat6 ,average='weighted'))\n",
    "print('Recall', recall_score(y_test, y_hat6,average='weighted'))\n",
    "print('f1-score', f1_score(y_test, y_hat6,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy19 0.5325985587113183\n",
      "Precision 0.5361134648890626\n",
      "Recall 0.5325985587113183\n",
      "f1-score 0.5308148634241694\n"
     ]
    }
   ],
   "source": [
    "print('Accurancy19', accuracy_score(y_test, y_hat19))\n",
    "print('Precision', precision_score(y_test, y_hat19,average='weighted' ))\n",
    "print('Recall', recall_score(y_test, y_hat19,average='weighted'))\n",
    "print('f1-score', f1_score(y_test, y_hat19,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.20      0.22      2406\n",
      "           2       0.22      0.40      0.29      2392\n",
      "           3       0.22      0.62      0.32      2302\n",
      "           4       0.70      0.09      0.16      2185\n",
      "           5       0.53      0.07      0.12      2192\n",
      "           6       0.97      0.18      0.30      2604\n",
      "\n",
      "    accuracy                           0.26     14081\n",
      "   macro avg       0.48      0.26      0.23     14081\n",
      "weighted avg       0.48      0.26      0.24     14081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.03      0.05      2406\n",
      "           2       0.19      0.77      0.30      2392\n",
      "           3       0.19      0.29      0.23      2302\n",
      "           4       0.67      0.03      0.06      2185\n",
      "           5       0.58      0.04      0.07      2192\n",
      "           6       0.96      0.08      0.15      2604\n",
      "\n",
      "    accuracy                           0.21     14081\n",
      "   macro avg       0.51      0.21      0.14     14081\n",
      "weighted avg       0.51      0.21      0.15     14081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DU MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "tfidf transfo loaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"Flask_journaux/src/models_pickle/file_model_fitted_svm_opti.pkl\", 'rb') as file_model:\n",
    "    lr = pickle.load(file_model)  \n",
    "    print ('Model loaded')\n",
    "\n",
    "with open(\"Flask_journaux/src/models_pickle/file_tfidf.pkl\", 'rb') as vector:\n",
    "    tfidf = pickle.load(vector)\n",
    "    print ('tfidf transfo loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bob mould trent an distors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x17935 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "titre ='Bob Mould, trente ans de distorsion'\n",
    "titre_nettoyé = nettoyage(titre)\n",
    "print(titre_nettoyé)\n",
    "query = tfidf.transform([titre_nettoyé])\n",
    "query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17935)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49691023, 0.29911828, 0.11191837, 0.09205312]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>jour_publication</th>\n",
       "      <th>categorie</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>« Même si mon conjoint en a fait plus, l’essen...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>emploi</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pennsylvanie, Michigan, Wisconsin... Le vote o...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>international</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simples spectateurs</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethiopie : le premier ministre annonce une rip...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>afrique</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lagardère : les clans Bolloré et Arnault négoc...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>economie</td>\n",
       "      <td>Le Monde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>Harry et Meghan déchus : quels membres de la f...</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>royautes</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>Nicolas Sarkozy : l'ancien Président explique ...</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>politique</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>Jahmil French : l'acteur de Degrassi : nouvell...</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>people</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>Meghan Markle accusée de harcèlement : les rév...</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>royautes</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>Sylvie Ortega hors de contrôle dans TPMP : la ...</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>people</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5501 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  titre jour_publication  \\\n",
       "0     « Même si mon conjoint en a fait plus, l’essen...       2020-11-04   \n",
       "1     Pennsylvanie, Michigan, Wisconsin... Le vote o...       2020-11-04   \n",
       "2                                   Simples spectateurs       2020-11-04   \n",
       "3     Ethiopie : le premier ministre annonce une rip...       2020-11-04   \n",
       "4     Lagardère : les clans Bolloré et Arnault négoc...       2020-11-04   \n",
       "...                                                 ...              ...   \n",
       "5496  Harry et Meghan déchus : quels membres de la f...       2021-03-03   \n",
       "5497  Nicolas Sarkozy : l'ancien Président explique ...       2021-03-03   \n",
       "5498  Jahmil French : l'acteur de Degrassi : nouvell...       2021-03-03   \n",
       "5499  Meghan Markle accusée de harcèlement : les rév...       2021-03-03   \n",
       "5500  Sylvie Ortega hors de contrôle dans TPMP : la ...       2021-03-03   \n",
       "\n",
       "          categorie   journal  \n",
       "0            emploi  Le Monde  \n",
       "1     international  Le Monde  \n",
       "2               NaN  Le Monde  \n",
       "3           afrique  Le Monde  \n",
       "4          economie  Le Monde  \n",
       "...             ...       ...  \n",
       "5496       royautes    Closer  \n",
       "5497      politique    Closer  \n",
       "5498         people    Closer  \n",
       "5499       royautes    Closer  \n",
       "5500         people    Closer  \n",
       "\n",
       "[5501 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 2\n",
    "\n",
    "df2= pd.read_csv('csv/data_cat2.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        mêm si conjoint fait essentiel tomb dos comme...\n",
       "1        pennsylvan michigan wisconsin vot ouvri blanc...\n",
       "2                                        simpl spectateur\n",
       "3        ethiop premi ministr annonc ripost apres atta...\n",
       "4        lagarder clan bollor arnault négocient sujet ...\n",
       "                              ...                        \n",
       "5496     harry meghan déchus quel membr famill royal v...\n",
       "5497     nicol sarkozy l'ancien président expliqu pour...\n",
       "5498     jahmil french l'acteur degrass nouvel géner m...\n",
       "5499     meghan markl accus harcel rével explos ancien...\n",
       "5500     sylv orteg hor contrôl dan tpmp veuv ludovic ...\n",
       "Name: titre, Length: 5501, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = df2.titre.map(lambda x: nettoyage(x))\n",
    "y2 = df2.journal.map(lambda x: encode_journal(x))\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_features = tfidf.transform(X2)\n",
    "pred2 = lr.predict(X2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy 0.4904562806762407\n",
      "Precision 0.4909159620515632\n",
      "Recall 0.4904562806762407\n",
      "f1-score 0.48892048417856576\n"
     ]
    }
   ],
   "source": [
    "print('Accurancy', accuracy_score(y2, pred2))\n",
    "print('Precision', precision_score(y2, pred2 ,average='weighted'))\n",
    "print('Recall', recall_score(y2, pred2,average='weighted'))\n",
    "print('f1-score', f1_score(y2, pred2,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                         user='root',\n",
    "                         password='Ludi24',\n",
    "                         db='journaux')\n",
    "# create cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "query_read = \"Select * from articles  where jour_publication<=date('2021-05-10') and  jour_publication>=date('2021-4-21')\"\n",
    "cursor.execute(query_read)\n",
    "raw = cursor.fetchall()\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "tfidf transfo loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator SVC from version 0.23.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"Flask_journaux/src/models_pickle/file_model_fitted_svm_opti.pkl\", 'rb') as file_model:\n",
    "    lr = pickle.load(file_model)  \n",
    "    print ('Model loaded')\n",
    "with open(\"Flask_journaux/src/models_pickle/file_tfidf.pkl\", 'rb') as vector:\n",
    "    tfidf = pickle.load(vector)\n",
    "    print ('tfidf transfo loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_article</th>\n",
       "      <th>titre</th>\n",
       "      <th>jour_publication</th>\n",
       "      <th>categorie</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37371</td>\n",
       "      <td>Jérémy Frérot : l'accouchement de Laure Manaud...</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>people</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37372</td>\n",
       "      <td>Rachida Dati : qui a volé les clefs de son app...</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>politique</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37373</td>\n",
       "      <td>Maurane : le touchant hommage de Pascal Obispo...</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>people</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37374</td>\n",
       "      <td>Gilbert Rozon : l'ex-juré de La France a un in...</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>people</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37375</td>\n",
       "      <td>Renaud : cet avertissement de Lola Séchan à so...</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>people</td>\n",
       "      <td>Closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>161930</td>\n",
       "      <td>«Time Capsule 2045», les as de la cachette</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>arts</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>161931</td>\n",
       "      <td>Turner Prize, le temps des militants</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>arts</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>161932</td>\n",
       "      <td>Rwanda : «Nous avons changé de méthode pour tr...</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>afrique</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>161933</td>\n",
       "      <td>Michel Fourniret, la fin de l’«ogre des Ardennes»</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>police / justice</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>161934</td>\n",
       "      <td>Grève dans les centres des impôts : «On nous d...</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>economie</td>\n",
       "      <td>Libération</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4176 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_article                                              titre  \\\n",
       "0          37371  Jérémy Frérot : l'accouchement de Laure Manaud...   \n",
       "1          37372  Rachida Dati : qui a volé les clefs de son app...   \n",
       "2          37373  Maurane : le touchant hommage de Pascal Obispo...   \n",
       "3          37374  Gilbert Rozon : l'ex-juré de La France a un in...   \n",
       "4          37375  Renaud : cet avertissement de Lola Séchan à so...   \n",
       "...          ...                                                ...   \n",
       "4171      161930         «Time Capsule 2045», les as de la cachette   \n",
       "4172      161931               Turner Prize, le temps des militants   \n",
       "4173      161932  Rwanda : «Nous avons changé de méthode pour tr...   \n",
       "4174      161933  Michel Fourniret, la fin de l’«ogre des Ardennes»   \n",
       "4175      161934  Grève dans les centres des impôts : «On nous d...   \n",
       "\n",
       "     jour_publication         categorie     journal  \n",
       "0          2021-05-10            people      Closer  \n",
       "1          2021-05-10         politique      Closer  \n",
       "2          2021-05-08            people      Closer  \n",
       "3          2021-05-08            people      Closer  \n",
       "4          2021-05-08            people      Closer  \n",
       "...               ...               ...         ...  \n",
       "4171       2021-05-10              arts  Libération  \n",
       "4172       2021-05-10              arts  Libération  \n",
       "4173       2021-05-10           afrique  Libération  \n",
       "4174       2021-05-10  police / justice  Libération  \n",
       "4175       2021-05-10          economie  Libération  \n",
       "\n",
       "[4176 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(raw, columns =[\"id_article\",\"titre\" ,\"jour_publication\" ,\"categorie\",\"journal\"  ])\n",
    "cursor.close()\n",
    "connection.close()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        jérémy frérot l'accouch laur manaudou deuxiem...\n",
       "1                              rachid dat vol clef appart\n",
       "2         mauran touch hommag pascal obispo an apres mort\n",
       "3        gilbert rozon l'exjur franc incroi talent acc...\n",
       "4        renaud cet avert lol séchan per refus fair va...\n",
       "                              ...                        \n",
       "4171                                    tim capsul cachet\n",
       "4172                                 turn priz temp milit\n",
       "4173                  rwand avon chang méthod traqu fugit\n",
       "4174                      michel fourniret fin ogre arden\n",
       "4175     grev dan centr impôt tous jour “appren contri...\n",
       "Name: titre, Length: 4176, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdata2 = df_test.titre.map(lambda x: nettoyage(x))\n",
    "ydata2 = df_test.journal.map(lambda x: encode_journal(x))\n",
    "Xdata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 22618 should be equal to 17935, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0390dfd67b49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mXdata2_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreddata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXdata2_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \"\"\"\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    491\u001b[0m                                  (X.shape[1], self.shape_fit_[0]))\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_fit_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0m\u001b[0;32m    494\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                              (X.shape[1], self.shape_fit_[1]))\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 22618 should be equal to 17935, the number of features at training time"
     ]
    }
   ],
   "source": [
    "Xdata2_features = tfidf.transform(Xdata2)\n",
    "preddata2 = lr.predict(Xdata2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accurancy', accuracy_score(ydata2ydata2ydata2ydata2, preddata2))\n",
    "print('Precision', precision_score(ydata2ydata2ydata2, preddata2 ,average='weighted'))\n",
    "print('Recall', recall_score(ydata2ydata2, preddata2,average='weighted'))\n",
    "print('f1-score', f1_score(ydata2, preddata2,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
